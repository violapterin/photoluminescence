<main class="document">
<div class="section">
<p class="paragraph">
<span class="phrase"><span class="serif-roman">Over the past several years, topics machine learning and optimization have been hot.</span></span> <span class="phrase"><span class="serif-roman">It appears to me that they have number of connections with communication theory and statistical inference too.</span></span> <span class="phrase"><span class="serif-roman">Actually, machine learning, statistical inference, and communication theory all address a situation, in which a source is mixed with addition degrees of freedom in a process, and is recovered in the destination.</span></span> <span class="phrase"><span class="serif-roman">They all can be fomulated as an optimization problem.</span></span>
</p>
</div>
<div class="section">
<p class="paragraph">
<span class="phrase"><span class="serif-roman">Consider the generic equation, possibly over vectors:</span></span>
</p>
<p class="paragraph">
<span class="phrase"><span class="math"><span class="math-plain">\(g\)</span><span class="math-bracket-square">\(\left[\vphantom{h \left[z ,\, x\right]}\right.\)</span><span class="math-plain">\(h\)</span><span class="math-bracket-square">\(\left[\vphantom{z ,\, x}\right.\)</span><span class="math-plain">\(z\)</span><span class="math-plain">\(,\,\)</span><span class="math-plain">\(x\)</span><span class="math-bracket-square">\(\left.\vphantom{z ,\, x}\right]\)</span><span class="math-bracket-square">\(\left.\vphantom{h \left[z ,\, x\right]}\right]\)</span><span class="math-plain">\(\;=\;\)</span><span class="math-bracket-angle">\(\left\langle\vphantom{w ,\, y}\right.\)</span><span class="math-plain">\(w\)</span><span class="math-plain">\(,\,\)</span><span class="math-plain">\(y\)</span><span class="math-bracket-angle">\(\left.\vphantom{w ,\, y}\right\rangle\)</span></span></span>
</p>
<p class="paragraph">
<span class="phrase"><span class="serif-roman">In statistical inference,</span> <span class="math"><span class="math-plain">\(x\)</span></span> <span class="serif-roman">is usually a boolean value, namely</span> <span class="math"><span class="math-plain">\(0\)</span></span> <span class="serif-roman">or</span> <span class="math"><span class="math-plain">\(1\)</span></span> <span class="serif-roman">standing for the null hypothesis and the alternative hypothesis, and</span> <span class="math"><span class="math-plain">\(y\)</span></span> <span class="serif-roman">the estimated hypothesis.</span></span> <span class="phrase"><span class="serif-roman">Moreover,</span> <span class="math"><span class="math-plain">\(z\)</span></span> <span class="serif-roman">is the event space, and</span> <span class="math"><span class="math-plain">\(h\)</span></span> <span class="serif-roman">the sample,</span> <span class="math"><span class="math-plain">\(g\)</span></span> <span class="serif-roman">the estimator.</span></span> <span class="phrase"><span class="serif-roman">A large sample property guarantees the success of estimation.</span></span>
</p>
<p class="paragraph">
<span class="phrase"><span class="serif-roman">In machine learning,</span> <span class="math"><span class="math-plain">\(x\)</span></span> <span class="serif-roman">is the collection of parameters of the hypothesis function, and</span> <span class="math"><span class="math-plain">\(y\)</span></span> <span class="serif-roman">the estimated collection of parameters.</span></span> <span class="phrase"><span class="serif-roman">Moreover,</span> <span class="math"><span class="math-plain">\(z\)</span></span> <span class="serif-roman">is the event space, and</span> <span class="math"><span class="math-plain">\(h\)</span></span> <span class="serif-roman">the data,</span> <span class="math"><span class="math-plain">\(g\)</span></span> <span class="serif-roman">the learning method.</span></span> <span class="phrase"><span class="serif-roman">A large sample property guarantees the success of estimation.</span></span> <span class="phrase"><span class="serif-roman">This is a more general than the case of statistical inference.</span></span>
</p>
<p class="paragraph">
<span class="phrase"><span class="serif-roman">Meanwhile, in communication theory,</span> <span class="math"><span class="math-plain">\(x\)</span></span> <span class="serif-roman">is the transmitter,</span> <span class="math"><span class="math-plain">\(y\)</span></span> <span class="serif-roman">the receiver,</span> <span class="serif-roman">and</span> <span class="math"><span class="math-plain">\(z\)</span></span> <span class="serif-roman">the noise.</span></span> <span class="phrase"><span class="serif-roman">Here the situation is more complicated;</span> <span class="serif-roman">in addition to</span> <span class="math"><span class="math-plain">\(z\)</span></span><span class="serif-roman">,</span> <span class="serif-roman">the large sample property of</span> <span class="math"><span class="math-plain">\(x\)</span></span> <span class="serif-roman">and</span> <span class="math"><span class="math-plain">\(y\)</span></span> <span class="serif-roman">are explored too.</span></span> <span class="phrase"><span class="serif-roman">In fact,</span> <span class="math"><span class="math-plain">\(x\)</span></span> <span class="serif-roman">not only is taken to be identically distributed per channel use, but is further encoded before being fed to the channel;</span> <span class="serif-roman">similarly,</span> <span class="math"><span class="math-plain">\(y\)</span></span> <span class="serif-roman">is further decoded after being output from the channel.</span></span>
</p>
<p class="paragraph">
<span class="phrase"><span class="serif-roman">These can be formulated as optimization problems.</span></span> <span class="phrase"><span class="serif-roman">Indeed, let</span> <span class="math"><span class="math-plain">\(x\)</span></span> <span class="serif-roman">be the collection of parameters, and</span> <span class="math"><span class="math-plain">\(z\)</span></span> <span class="serif-roman">the sample points.</span></span> <span class="phrase"><span class="serif-roman">Then</span> <span class="math"><span class="math-plain">\(h\)</span></span> <span class="serif-roman">is the target function over</span> <span class="math"><span class="math-plain">\(x\)</span></span><span class="serif-roman">,</span> <span class="serif-roman">and</span> <span class="math"><span class="math-plain">\(g\)</span></span> <span class="serif-roman">the optimization algorithm over</span> <span class="math"><span class="math-plain">\(y\)</span></span><span class="serif-roman">.</span></span> <span class="phrase"><span class="serif-roman">A large sample property guarantees the success of optimization, regardless of the chosen</span> <span class="math"><span class="math-plain">\(z\)</span></span><span class="serif-roman">.</span></span>
</p>
</div>
<div class="break">
<span class="phrase">&emsp;</span> <span class="phrase">❦</span> <span class="phrase">&emsp;</span> <span class="phrase">❦</span> <span class="phrase">&emsp;</span> <span class="phrase">❦</span>
</div>
<div class="section">
<p class="paragraph">
<span class="phrase"><span class="serif-roman">❧</span> <em class="serif-italic">September 20, 2021</em></span>
</p>
</div>
</main>